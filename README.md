# machine learning 

## Introduction：
This project is the implementation of the algorithems based on the courses Machine Learning Foundation and Machine Learning Technique from NTU.

## Contents：
  * `AdaBoost.py:` adaptive boosting classifier with the base learner decision stump.

  * `DecisionStump.py:` decision stump supporting weighted data.

  * `DecisionTree.py:` an implementation of the CART algorithem.

  * `GBDTRegressor.py:` a gradient boosting regressor using pruned decision tree, with the mean square error as loss function.

  * `KNN.py:` the k-nearest neighbour classifier and regressor.

  * `Kmeans.py:` K-means clustering.

  * `LinearRegressor.py:` linear regression,supporting L2-regularized(ridge) regression and kernel ridge regression(linear,polynomial and gaussion)

  * `LogisticRegressor.py:` logistic regression, L2-regularized LR based on SGD.

  * `MatrixFactorization.py:` matrix factorization, supporting alternative least square(ALS) and SGD.

  * `NaiveBayes.py:` naive bayes classifier, supporting multinomial and gaussion.

  * `NeuralNetwork.py:` an implementation of the neural network, training with back propagation(BP).

  * `NonSeparablePerceptron.py:` non-seperable perceptron, training with pocket algorithem.

  * `PCA.py:` Principle Component Analysis with SVD and Linear Discriminant Analysis(LDA).

  * `Perceptron.py:` an implementation of peceptron with PLA algorithem.

  * `RandomForest.py:` a simple implementation of random forest classifier, supporting feature selection with the OOB error.

  * `SVM.py:` soft margin SVM, probabilistic SVM and Support Vector Regression(SVR), supporting linear, polynomial and gaussion kernels.

